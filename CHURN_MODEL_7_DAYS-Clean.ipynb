{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymssql\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "import datetime as dt\n",
    "import warnings\n",
    "import dateutil.relativedelta\n",
    "from sklearn.model_selection import train_test_split as train\n",
    "from mlxtend.evaluate import lift_score\n",
    "from sklearn.metrics import make_scorer, roc_curve, auc, roc_auc_score\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "import lightgbm as lgbm \n",
    "from sklearn import ensemble\n",
    "import uncertainties\n",
    "import random\n",
    "from random import randint\n",
    "import seaborn as sns\n",
    "from uncertainties import ufloat\n",
    "from sklearn.metrics import precision_recall_curve, classification_report\n",
    "from dateutil.relativedelta import relativedelta\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.options.display.max_columns = 500\n",
    "pd.options.display.max_rows = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных, смена типов, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop('CNT_VISITS_DAY', axis=1)#сережа должен убрать из витрины\n",
    "df['Datum'] = pd.to_datetime(df['Datum'])\n",
    "df['CNT_VISITS_WEEK'] = df['CNT_VISITS_WEEK'].astype(np.float16)\n",
    "df['CNT_VISITS_MONTH'] = df['CNT_VISITS_MONTH'].astype(np.float16)\n",
    "df['CNT_VISITS_THREE_MONTH'] = df['CNT_VISITS_THREE_MONTH'].astype(np.float16)\n",
    "df['CNT_VISITS_DAY_TO_LAST_WEEK'] = df['CNT_VISITS_DAY_TO_LAST_WEEK'].astype(np.float16)\n",
    "df['DIV_VISITS_week_TO_AVG_VISITS_SIX_WEEK'] = df['DIV_VISITS_week_TO_AVG_VISITS_SIX_WEEK'].astype(np.float64)\n",
    "df['DIV_VISITS_month_TO_LAST_MONTH'] = df['DIV_VISITS_month_TO_LAST_MONTH'].astype(np.float64)\n",
    "df['DIV_VISITS_month_TO_AVG_VISITS_THREE_MONTH'] = df['DIV_VISITS_month_TO_AVG_VISITS_THREE_MONTH'].astype(np.float64)\n",
    "df['DIV_UNITS_IN_CHECK_SIX_WEEK'] = df['DIV_UNITS_IN_CHECK_SIX_WEEK'].astype(np.float64)\n",
    "df['DIV_UNITS_IN_CHECK_THREE_week'] = df['DIV_UNITS_IN_CHECK_THREE_week'].astype(np.float64)\n",
    "df['DIV_UNITS_IN_CHECK_TO_LAST_MONTH'] = df['DIV_UNITS_IN_CHECK_TO_LAST_MONTH'].astype(np.float64)\n",
    "df['DIV_UNITS_IN_CHECK_WEEK'] = df['DIV_UNITS_IN_CHECK_WEEK'].astype(np.float64)\n",
    "df['AVG_COST_PRODUCT_IN_CHECK'] = df['AVG_COST_PRODUCT_IN_CHECK'].astype(np.float64)\n",
    "df['AVG_UNITS_IN_CHECK'] = df['AVG_UNITS_IN_CHECK'].astype(np.float64)\n",
    "df['AVG_SUM_CHECK'] = df['AVG_SUM_CHECK'].astype(np.float64)\n",
    "df['DIV_VISITS_week_TO_AVG_VISITS_THREE_WEEK'] = df['DIV_VISITS_week_TO_AVG_VISITS_THREE_WEEK'].astype(np.float64)\n",
    "df['DIV_VISITS_week_TO_AVG_VISITS_EIGHT_WEEK'] = df['DIV_VISITS_week_TO_AVG_VISITS_EIGHT_WEEK'].astype(np.float64)\n",
    "df['DIV_VISITS_week_TO_AVG_VISITS_FOUR_WEEK'] = df['DIV_VISITS_week_TO_AVG_VISITS_FOUR_WEEK'].astype(np.float64)\n",
    "df['COMM_AGREEMENT'] = df['COMM_AGREEMENT'].astype(np.float16)\n",
    "df['EMPLOYEE'] = df['EMPLOYEE'].astype(np.float16)\n",
    "df['FACT_FAVE_STORE'] = df['FACT_FAVE_STORE'].astype(np.float16)\n",
    "df['CNT_VISITS_WEEK_TO_LAST_WEEK'] = df['CNT_VISITS_WEEK_TO_LAST_WEEK'].astype(np.float16)\n",
    "# преобразование в количественный признак, если в витрине не в числовом формате\n",
    "#df.at[df['MEMS_TYPE'] == 'Индивидуальное', 'MEMS_TYPE'] = 0\n",
    "#df.at[df['MEMS_TYPE'] == 'Анонимное', 'MEMS_TYPE'] = 1\n",
    "# не определен тип клиента \n",
    "df.at[df['MEMS_TYPE'].isnull(), 'MEMS_TYPE'] = 2 \n",
    "df['div_unique_category_lvl_3_week_last_week'] = df['div_unique_category_lvl_3_week_last_week'].astype(np.float64)\n",
    "df['activity_key_kat_week'] = df['activity_key_kat_week'].astype(np.float64)\n",
    "df['activity_key_kat_1month'] = df['activity_key_kat_1month'].astype(np.float64)\n",
    "df['activity_key_kat_3month'] = df['activity_key_kat_3month'].astype(np.float64)\n",
    "df['div_unique_category_lvl_3_month_three_last_month'] = df['div_unique_category_lvl_3_month_three_last_month'].astype(np.float64)\n",
    "df['div_unique_category_lvl_3_month_six_last_month'] = df['div_unique_category_lvl_3_month_six_last_month'].astype(np.float64)\n",
    "df['activity_key_kat_6month'] = df['activity_key_kat_6month'].astype(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание целевой переменной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.sort_values(by='Datum', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Churn'] = df['cnt_days_last_visit'].apply(lambda x: 1 if x >=7 else 0)\n",
    "df['Churn'] = df.groupby('mems_id')['Churn'].shift(-1)\n",
    "df=df.dropna(subset=['Churn'])\n",
    "df['Churn']=df['Churn'].astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разделение на папки для обучения и тестирования "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Fold_1'] = 0 \n",
    "df['Fold_2'] = 0 \n",
    "df['Fold_3'] = 0 \n",
    "df['Validation'] = 0\n",
    "\n",
    "df.loc[(df['Datum'] >= '2018-06-01') & (df['Datum'] <= '2018-09-30'), 'Fold_1'] = 'train'\n",
    "df.loc[(df['Datum'] >= '2018-10-15') & (df['Datum'] <= '2018-11-30'), 'Fold_1'] = 'test'\n",
    "df.loc[(df['Datum'] >= '2018-08-01') & (df['Datum'] <= '2018-12-31'), 'Fold_2'] = 'train'\n",
    "df.loc[(df['Datum'] >= '2019-01-15') & (df['Datum'] <= '2019-02-28'), 'Fold_2'] = 'test'\n",
    "df.loc[(df['Datum'] >= '2018-10-01') & (df['Datum'] <= '2019-02-28'), 'Fold_3'] = 'train'\n",
    "df.loc[(df['Datum'] >= '2019-03-15') & (df['Datum'] <= '2019-04-30'), 'Fold_3'] = 'test'\n",
    "df.loc[(df['Datum'] >= '2018-07-01') & (df['Datum'] <= '2019-03-31'), 'Validation'] = 'train'\n",
    "df.loc[(df['Datum'] >= '2019-06-01') & (df['Datum'] <= '2019-08-31'), 'Validation'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_hdf('/mnt/cda/week_churn_kat_1802.hdf', \"df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Считываем собранный файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf('/mnt/cda/week_churn_kat_1802.hdf', \"df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во уникальных клиентов 2027802\n",
      "\n",
      "Кол-во дат за весь период 61\n",
      "\n",
      "Первая дата 2018-06-03 00:00:00\n",
      "\n",
      "Последняя дата 2019-07-28 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print (\"Кол-во уникальных клиентов\", df['mems_id'].nunique())\n",
    "print ()\n",
    "print (\"Кол-во дат за весь период\", df['Datum'].nunique())\n",
    "print ()\n",
    "print (\"Первая дата\", df['Datum'].min())\n",
    "print ()\n",
    "print (\"Последняя дата\", df['Datum'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем набор данных для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cv = df[(df['Fold_1'] == 'train') | (df['Fold_2'] == 'train') |\\\n",
    "              (df['Fold_1'] == 'test') | (df['Fold_2'] == 'test')|\\\n",
    "             (df['Fold_3'] == 'train') | (df['Fold_3'] == 'test')].sample(500000).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Индексы данных для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ind_1 = train_cv[train_cv['Fold_1'] == 'train'].index.values.astype(int)\n",
    "test_ind_1 = train_cv[train_cv['Fold_1'] == 'test'].index.values.astype(int)\n",
    "train_ind_2 = train_cv[train_cv['Fold_2'] == 'train'].index.values.astype(int)\n",
    "test_ind_2 = train_cv[train_cv['Fold_2'] == 'test'].index.values.astype(int)\n",
    "train_ind_3 = train_cv[train_cv['Fold_3'] == 'train'].index.values.astype(int)\n",
    "test_ind_3 = train_cv[train_cv['Fold_3'] == 'test'].index.values.astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Целевая переменная и признаки для обучения модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер тестовой и убочающей выборки (500000, 42) (500000,)\n"
     ]
    }
   ],
   "source": [
    "y_train_cv = train_cv['Churn']\n",
    "X_train_cv = train_cv.drop(['index', 'Churn', 'mems_id', 'Datum', \n",
    "                              'Fold_1', 'Fold_2', 'Fold_3', 'Validation'],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Бизнес метрика для обучения модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_asymmetric_train(  y_true, y_pred ):# для грида такой порядок переменных\n",
    "    function=np.where((y_pred>0.5)&(y_true==0), -1000, 0)\n",
    "    function2=np.where((y_pred>0.5)&(y_true==1), 1, 0)\n",
    "    res=np.mean(function+function2).astype(float)\n",
    "    return  res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "my_func = make_scorer(custom_asymmetric_train, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генератор для разделения на обучающую и тестовую выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(train_cv):\n",
    "    i = 1\n",
    "    while i <= 3:\n",
    "        train_ind_1 = train_cv[train_cv['Fold_'+str(i)] == 'train'].index.values.astype(int)\n",
    "        test_ind_1 = train_cv[train_cv['Fold_'+str(i)] == 'test'].index.values.astype(int)\n",
    "        yield train_ind_1, test_ind_1\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = lgbm.LGBMClassifier(silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridParams = {\n",
    "    'learning_rate': [0.5, 0.2, 0.7],\n",
    "    'n_estimators':  [450, 500, 550],\n",
    "    'num_leaves': [6, 5, 4, 3],\n",
    "    'boosting_type' : ['rf'],\n",
    "    'objective' : ['binary'],\n",
    "    'random_state' : [501],\n",
    "    \"max_depth\":[2, 3, 4, 5],\n",
    "    'bagging_fraction':[0.1 ,0.3, 0.5,  0.6],\n",
    "    'bagging_freq': [1],\n",
    "    'colsample_bytree' : [0.5, 0.7, 1],\n",
    "    'subsample' : [0.1, 0.5],\n",
    "    'reg_alpha' : [5, 3, 1],\n",
    "    'reg_lambda' : [0.4, 0.6, 0.8, 1]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15552 candidates, totalling 46656 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=11)]: Using backend LokyBackend with 11 concurrent workers.\n",
      "[Parallel(n_jobs=11)]: Done  10 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=11)]: Done 106 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=11)]: Done 266 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=11)]: Done 490 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=11)]: Done 778 tasks      | elapsed: 73.3min\n",
      "[Parallel(n_jobs=11)]: Done 1130 tasks      | elapsed: 79.4min\n",
      "[Parallel(n_jobs=11)]: Done 1546 tasks      | elapsed: 86.6min\n",
      "[Parallel(n_jobs=11)]: Done 2026 tasks      | elapsed: 94.8min\n",
      "[Parallel(n_jobs=11)]: Done 2570 tasks      | elapsed: 104.6min\n",
      "[Parallel(n_jobs=11)]: Done 3178 tasks      | elapsed: 115.3min\n",
      "[Parallel(n_jobs=11)]: Done 3850 tasks      | elapsed: 127.0min\n",
      "[Parallel(n_jobs=11)]: Done 4586 tasks      | elapsed: 139.6min\n",
      "[Parallel(n_jobs=11)]: Done 5386 tasks      | elapsed: 153.7min\n",
      "[Parallel(n_jobs=11)]: Done 6250 tasks      | elapsed: 170.9min\n",
      "[Parallel(n_jobs=11)]: Done 7178 tasks      | elapsed: 189.5min\n",
      "[Parallel(n_jobs=11)]: Done 8170 tasks      | elapsed: 209.9min\n",
      "[Parallel(n_jobs=11)]: Done 9226 tasks      | elapsed: 230.8min\n",
      "[Parallel(n_jobs=11)]: Done 10346 tasks      | elapsed: 253.4min\n",
      "[Parallel(n_jobs=11)]: Done 11530 tasks      | elapsed: 281.3min\n",
      "[Parallel(n_jobs=11)]: Done 12778 tasks      | elapsed: 311.0min\n",
      "[Parallel(n_jobs=11)]: Done 14090 tasks      | elapsed: 342.6min\n",
      "[Parallel(n_jobs=11)]: Done 15466 tasks      | elapsed: 375.7min\n",
      "[Parallel(n_jobs=11)]: Done 16906 tasks      | elapsed: 401.2min\n",
      "[Parallel(n_jobs=11)]: Done 18410 tasks      | elapsed: 427.2min\n",
      "[Parallel(n_jobs=11)]: Done 19978 tasks      | elapsed: 454.5min\n",
      "[Parallel(n_jobs=11)]: Done 21610 tasks      | elapsed: 485.0min\n",
      "[Parallel(n_jobs=11)]: Done 23306 tasks      | elapsed: 518.9min\n",
      "[Parallel(n_jobs=11)]: Done 25066 tasks      | elapsed: 554.2min\n",
      "[Parallel(n_jobs=11)]: Done 26890 tasks      | elapsed: 594.1min\n",
      "[Parallel(n_jobs=11)]: Done 28778 tasks      | elapsed: 639.3min\n",
      "[Parallel(n_jobs=11)]: Done 30730 tasks      | elapsed: 686.1min\n",
      "[Parallel(n_jobs=11)]: Done 32746 tasks      | elapsed: 723.5min\n",
      "[Parallel(n_jobs=11)]: Done 34826 tasks      | elapsed: 819.6min\n",
      "[Parallel(n_jobs=11)]: Done 36970 tasks      | elapsed: 858.2min\n",
      "[Parallel(n_jobs=11)]: Done 39178 tasks      | elapsed: 902.6min\n",
      "[Parallel(n_jobs=11)]: Done 41450 tasks      | elapsed: 948.1min\n",
      "[Parallel(n_jobs=11)]: Done 43786 tasks      | elapsed: 1003.3min\n",
      "[Parallel(n_jobs=11)]: Done 46186 tasks      | elapsed: 1061.2min\n",
      "[Parallel(n_jobs=11)]: Done 46656 out of 46656 | elapsed: 1072.6min finished\n"
     ]
    }
   ],
   "source": [
    "grid_lgbm = GridSearchCV(mdl, gridParams,\n",
    "                        verbose=3,\n",
    "                        cv = generator(train_cv),\n",
    "                         n_jobs=11, scoring=my_func)\n",
    "\n",
    "grid_3 = grid_lgbm.fit(X_train_cv, y_train_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ошибка на обучении:\", grid_3.best_score_)\n",
    "print(\"Модель с лучшими параметрами:\", grid_3.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучающий и тестовый набор данных для модели с лучшими параметрами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df[df['Validation'] == 'test']\n",
    "\n",
    "\n",
    "y_test = df_test['Churn']\n",
    "X_test = df_test.drop(['Churn', 'mems_id', 'Datum', \n",
    "                              'Fold_1', 'Fold_2', 'Fold_3', 'Validation'], axis=1)\n",
    "\n",
    "df_train = df[df['Validation'] == 'train']\n",
    "\n",
    "y_train = df_train['Churn']\n",
    "X_train = df_train.drop(['Churn', 'mems_id', 'Datum', \n",
    "                              'Fold_1', 'Fold_2', 'Fold_3', 'Validation'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели с ранним завершением, чтобы выбрать лучшую модель по бизнес метрике "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[5]\ttraining's busines_metric: -170.635\n",
      "[10]\ttraining's busines_metric: -147.465\n",
      "[15]\ttraining's busines_metric: -140.648\n",
      "[20]\ttraining's busines_metric: -138.333\n",
      "[25]\ttraining's busines_metric: -138.203\n",
      "[30]\ttraining's busines_metric: -136.527\n",
      "[35]\ttraining's busines_metric: -135.522\n",
      "[40]\ttraining's busines_metric: -133.938\n",
      "[45]\ttraining's busines_metric: -133.693\n",
      "[50]\ttraining's busines_metric: -132.897\n",
      "[55]\ttraining's busines_metric: -132.474\n",
      "[60]\ttraining's busines_metric: -132.771\n",
      "[65]\ttraining's busines_metric: -133.429\n",
      "[70]\ttraining's busines_metric: -133.756\n",
      "[75]\ttraining's busines_metric: -133.76\n",
      "[80]\ttraining's busines_metric: -133.829\n",
      "[85]\ttraining's busines_metric: -133.841\n",
      "[90]\ttraining's busines_metric: -134.036\n",
      "[95]\ttraining's busines_metric: -134.252\n",
      "[100]\ttraining's busines_metric: -134.501\n",
      "[105]\ttraining's busines_metric: -133.898\n",
      "[110]\ttraining's busines_metric: -134.12\n",
      "[115]\ttraining's busines_metric: -133.903\n",
      "[120]\ttraining's busines_metric: -134.147\n",
      "[125]\ttraining's busines_metric: -134.037\n",
      "[130]\ttraining's busines_metric: -134.428\n",
      "[135]\ttraining's busines_metric: -134.508\n",
      "[140]\ttraining's busines_metric: -134.506\n",
      "[145]\ttraining's busines_metric: -134.368\n",
      "[150]\ttraining's busines_metric: -134.548\n",
      "[155]\ttraining's busines_metric: -134.536\n",
      "[160]\ttraining's busines_metric: -134.813\n",
      "[165]\ttraining's busines_metric: -134.958\n",
      "[170]\ttraining's busines_metric: -134.816\n",
      "[175]\ttraining's busines_metric: -134.626\n",
      "[180]\ttraining's busines_metric: -134.685\n",
      "[185]\ttraining's busines_metric: -134.955\n",
      "[190]\ttraining's busines_metric: -135.028\n",
      "[195]\ttraining's busines_metric: -135.011\n",
      "[200]\ttraining's busines_metric: -135.132\n",
      "[205]\ttraining's busines_metric: -134.875\n",
      "[210]\ttraining's busines_metric: -134.918\n",
      "[215]\ttraining's busines_metric: -134.819\n",
      "[220]\ttraining's busines_metric: -134.588\n",
      "[225]\ttraining's busines_metric: -134.58\n",
      "[230]\ttraining's busines_metric: -134.532\n",
      "[235]\ttraining's busines_metric: -134.624\n",
      "[240]\ttraining's busines_metric: -134.555\n",
      "[245]\ttraining's busines_metric: -134.683\n",
      "[250]\ttraining's busines_metric: -134.834\n",
      "[255]\ttraining's busines_metric: -134.71\n",
      "[260]\ttraining's busines_metric: -134.738\n",
      "[265]\ttraining's busines_metric: -134.67\n",
      "[270]\ttraining's busines_metric: -134.689\n",
      "[275]\ttraining's busines_metric: -134.803\n",
      "[280]\ttraining's busines_metric: -134.664\n",
      "[285]\ttraining's busines_metric: -134.796\n",
      "[290]\ttraining's busines_metric: -134.709\n",
      "[295]\ttraining's busines_metric: -134.702\n",
      "[300]\ttraining's busines_metric: -134.63\n",
      "[305]\ttraining's busines_metric: -134.758\n",
      "[310]\ttraining's busines_metric: -134.738\n",
      "[315]\ttraining's busines_metric: -134.761\n",
      "[320]\ttraining's busines_metric: -134.772\n",
      "[325]\ttraining's busines_metric: -134.905\n",
      "[330]\ttraining's busines_metric: -134.741\n",
      "[335]\ttraining's busines_metric: -134.797\n",
      "[340]\ttraining's busines_metric: -134.776\n",
      "[345]\ttraining's busines_metric: -134.89\n",
      "[350]\ttraining's busines_metric: -134.593\n",
      "[355]\ttraining's busines_metric: -134.515\n",
      "[360]\ttraining's busines_metric: -134.531\n",
      "[365]\ttraining's busines_metric: -134.559\n",
      "[370]\ttraining's busines_metric: -134.516\n",
      "[375]\ttraining's busines_metric: -134.618\n",
      "[380]\ttraining's busines_metric: -134.661\n",
      "[385]\ttraining's busines_metric: -134.64\n",
      "[390]\ttraining's busines_metric: -134.441\n",
      "[395]\ttraining's busines_metric: -134.442\n",
      "[400]\ttraining's busines_metric: -134.511\n",
      "[405]\ttraining's busines_metric: -134.326\n",
      "[410]\ttraining's busines_metric: -134.342\n",
      "[415]\ttraining's busines_metric: -134.405\n",
      "[420]\ttraining's busines_metric: -134.817\n",
      "[425]\ttraining's busines_metric: -134.768\n",
      "[430]\ttraining's busines_metric: -134.642\n",
      "[435]\ttraining's busines_metric: -134.633\n",
      "[440]\ttraining's busines_metric: -134.565\n",
      "[445]\ttraining's busines_metric: -134.451\n",
      "[450]\ttraining's busines_metric: -134.502\n",
      "[455]\ttraining's busines_metric: -134.38\n",
      "[460]\ttraining's busines_metric: -134.402\n",
      "[465]\ttraining's busines_metric: -134.487\n",
      "[470]\ttraining's busines_metric: -134.419\n",
      "[475]\ttraining's busines_metric: -134.393\n",
      "[480]\ttraining's busines_metric: -134.301\n",
      "[485]\ttraining's busines_metric: -134.293\n",
      "[490]\ttraining's busines_metric: -134.356\n",
      "[495]\ttraining's busines_metric: -134.285\n",
      "[500]\ttraining's busines_metric: -134.234\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[56]\ttraining's busines_metric: -132.138\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(bagging_fraction=0.3, boosting_type='gbdt', class_weight=None,\n",
       "               colsample_bytree=0.5, importance_type='split', learning_rate=0.2,\n",
       "               max_depth=2, metric='custom', min_child_samples=20,\n",
       "               min_child_weight=0.001, min_split_gain=0.0, n_estimators=500,\n",
       "               n_jobs=-1, num_leaves=3, objective='binary', random_state=501,\n",
       "               reg_alpha=0.1, reg_lambda=1, silent=True, subsample=0.1,\n",
       "               subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl_metric = lgbm.LGBMClassifier(**grid_3.best_params_, metric='custom')\n",
    "\n",
    "mdl_metric.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "   eval_metric=custom_asymmetric_train,\n",
    "    early_stopping_rounds=1000,\n",
    "    verbose=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict, {'training': {'busines_metric': -132.1383352914261}})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl_metric.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка процентного соотношения ошибок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_percent(y_pred, y_true):\n",
    "    residual = (2*y_true - y_pred)\n",
    "    true=np.sum(np.where(residual==1, 1, 0))/len(y_true)\n",
    "    false=np.sum(np.where(residual==-1, 1, 0))/len(y_true)\n",
    "    falsep=np.sum(np.where(residual==2, 1, 0))/len(y_true)\n",
    "    return 'true_neg:', true, 'false_neg:', false, 'false_p:', falsep, 'true_p:', 1-false-true-falsep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('true_neg:',\n",
       " 0.6550504197068816,\n",
       " 'false_neg:',\n",
       " 0.13279338571113297,\n",
       " 'false_p:',\n",
       " 0.061432373069966385,\n",
       " 'true_p:',\n",
       " 0.15072382151201905)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_percent(mdl_metric.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 0.769\n",
      "Accuracy score (validation): 0.806\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score (training): {0:.3f}\".format(mdl_metric.score(X_train, y_train)))\n",
    "print(\"Accuracy score (validation): {0:.3f}\".format(mdl_metric.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Churn_forest2802.pkl\", 'wb') as fid:\n",
    "    pickle.dump(mdl_metric, fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
