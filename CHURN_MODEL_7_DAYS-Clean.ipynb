{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymssql\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "import datetime as dt\n",
    "import warnings\n",
    "import dateutil.relativedelta\n",
    "from sklearn.model_selection import train_test_split as train\n",
    "from mlxtend.evaluate import lift_score\n",
    "from sklearn.metrics import make_scorer, roc_curve, auc, roc_auc_score\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "import lightgbm as lgbm \n",
    "from sklearn import ensemble\n",
    "import uncertainties\n",
    "import random\n",
    "from random import randint\n",
    "import seaborn as sns\n",
    "from uncertainties import ufloat\n",
    "from sklearn.metrics import precision_recall_curve, classification_report\n",
    "from dateutil.relativedelta import relativedelta\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.options.display.max_columns = 500\n",
    "pd.options.display.max_rows = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from sqlalchemy import create_engine, event, DateTime, Column, String, MetaData, Integer, \\\n",
    "    Binary, PrimaryKeyConstraint, Date\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker, Session\n",
    "from contextlib import contextmanager\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DbConfig:\n",
    "    db_server = \"10.252.4.116\"\n",
    "    pwd = \"MxGX91Zy\"\n",
    "    uid = \"ext-E.Stepanova\"\n",
    "    db_name = \"DWH_Globus\"\n",
    "    driver = r\"{ODBC Driver 17 for SQL Server}\"\n",
    "    params = quote_plus(\n",
    "        'DRIVER={DRIVER};SERVER={DB_SERVER};DATABASE={DB_NAME};UID={UID};PWD={PWD}'.format(\n",
    "            DB_SERVER=db_server, DB_NAME=db_name, UID=uid, PWD=pwd, DRIVER=driver\n",
    "        ))\n",
    "    print(params)\n",
    "    conn_str = 'mssql+pyodbc:///?odbc_connect={}'.format(params)\n",
    "\n",
    "\n",
    "class Db:\n",
    "    def __init__(self):\n",
    "        self._db_conf = DbConfig()\n",
    "        self.engine = None\n",
    "\n",
    "    def create_engine(self):\n",
    "        if self.engine is None:\n",
    "            self.engine = create_engine(self._db_conf.conn_str)\n",
    "\n",
    "        @event.listens_for(self.engine, 'before_cursor_execute')\n",
    "        def receive_before_cursor_execute(conn, cursor, statement, params, context, executemany):\n",
    "            if executemany:\n",
    "                cursor.fast_executemany = True\n",
    "                cursor.commit()\n",
    "\n",
    "    @contextmanager\n",
    "    def open_session(self):\n",
    "        \"\"\"Provide a transactional scope around a series of operations.\"\"\"\n",
    "        session: Session = sessionmaker(bind=self.engine)()\n",
    "        try:\n",
    "            yield session\n",
    "            session.commit()\n",
    "        except:\n",
    "            session.rollback()\n",
    "            raise\n",
    "        finally:\n",
    "            session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_sql_query_churn=\"\"\"select * from DWH_Globus.[cda_prom].[ForKorusTempChurnWeeklyKAT_2020] with (nolock) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Db()\n",
    "db.create_engine()\n",
    "chunks = []\n",
    "for chunk in pd.read_sql(str_sql_query_churn, con=db.engine, chunksize = 10**5):\n",
    "    chunks.append(chunk)\n",
    "df= pd.concat(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных, смена типов, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop('CNT_VISITS_DAY', axis=1)#сережа должен убрать из витрины\n",
    "df['Datum'] = pd.to_datetime(df['Datum'])\n",
    "df['CNT_VISITS_WEEK'] = df['CNT_VISITS_WEEK'].astype(np.float16)\n",
    "df['CNT_VISITS_MONTH'] = df['CNT_VISITS_MONTH'].astype(np.float16)\n",
    "df['CNT_VISITS_THREE_MONTH'] = df['CNT_VISITS_THREE_MONTH'].astype(np.float16)\n",
    "df['CNT_VISITS_DAY_TO_LAST_WEEK'] = df['CNT_VISITS_DAY_TO_LAST_WEEK'].astype(np.float16)\n",
    "df['DIV_VISITS_week_TO_AVG_VISITS_SIX_WEEK'] = df['DIV_VISITS_week_TO_AVG_VISITS_SIX_WEEK'].astype(np.float64)\n",
    "df['DIV_VISITS_month_TO_LAST_MONTH'] = df['DIV_VISITS_month_TO_LAST_MONTH'].astype(np.float64)\n",
    "df['DIV_VISITS_month_TO_AVG_VISITS_THREE_MONTH'] = df['DIV_VISITS_month_TO_AVG_VISITS_THREE_MONTH'].astype(np.float64)\n",
    "df['DIV_UNITS_IN_CHECK_SIX_WEEK'] = df['DIV_UNITS_IN_CHECK_SIX_WEEK'].astype(np.float64)\n",
    "df['DIV_UNITS_IN_CHECK_THREE_week'] = df['DIV_UNITS_IN_CHECK_THREE_week'].astype(np.float64)\n",
    "df['DIV_UNITS_IN_CHECK_TO_LAST_MONTH'] = df['DIV_UNITS_IN_CHECK_TO_LAST_MONTH'].astype(np.float64)\n",
    "df['DIV_UNITS_IN_CHECK_WEEK'] = df['DIV_UNITS_IN_CHECK_WEEK'].astype(np.float64)\n",
    "df['AVG_COST_PRODUCT_IN_CHECK'] = df['AVG_COST_PRODUCT_IN_CHECK'].astype(np.float64)\n",
    "df['AVG_UNITS_IN_CHECK'] = df['AVG_UNITS_IN_CHECK'].astype(np.float64)\n",
    "df['AVG_SUM_CHECK'] = df['AVG_SUM_CHECK'].astype(np.float64)\n",
    "df['DIV_VISITS_week_TO_AVG_VISITS_THREE_WEEK'] = df['DIV_VISITS_week_TO_AVG_VISITS_THREE_WEEK'].astype(np.float64)\n",
    "df['DIV_VISITS_week_TO_AVG_VISITS_EIGHT_WEEK'] = df['DIV_VISITS_week_TO_AVG_VISITS_EIGHT_WEEK'].astype(np.float64)\n",
    "df['DIV_VISITS_week_TO_AVG_VISITS_FOUR_WEEK'] = df['DIV_VISITS_week_TO_AVG_VISITS_FOUR_WEEK'].astype(np.float64)\n",
    "df['COMM_AGREEMENT'] = df['COMM_AGREEMENT'].astype(np.float16)\n",
    "df['EMPLOYEE'] = df['EMPLOYEE'].astype(np.float16)\n",
    "df['FACT_FAVE_STORE'] = df['FACT_FAVE_STORE'].astype(np.float16)\n",
    "df['CNT_VISITS_WEEK_TO_LAST_WEEK'] = df['CNT_VISITS_WEEK_TO_LAST_WEEK'].astype(np.float16)\n",
    "# преобразование в количественный признак, если в витрине не в числовом формате\n",
    "#df.at[df['MEMS_TYPE'] == 'Индивидуальное', 'MEMS_TYPE'] = 0\n",
    "#df.at[df['MEMS_TYPE'] == 'Анонимное', 'MEMS_TYPE'] = 1\n",
    "# не определен тип клиента \n",
    "df.at[df['MEMS_TYPE'].isnull(), 'MEMS_TYPE'] = 2 \n",
    "df['div_unique_category_lvl_3_week_last_week'] = df['div_unique_category_lvl_3_week_last_week'].astype(np.float64)\n",
    "df['activity_key_kat_week'] = df['activity_key_kat_week'].astype(np.float64)\n",
    "df['activity_key_kat_1month'] = df['activity_key_kat_1month'].astype(np.float64)\n",
    "df['activity_key_kat_3month'] = df['activity_key_kat_3month'].astype(np.float64)\n",
    "df['div_unique_category_lvl_3_month_three_last_month'] = df['div_unique_category_lvl_3_month_three_last_month'].astype(np.float64)\n",
    "df['div_unique_category_lvl_3_month_six_last_month'] = df['div_unique_category_lvl_3_month_six_last_month'].astype(np.float64)\n",
    "df['activity_key_kat_6month'] = df['activity_key_kat_6month'].astype(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание целевой переменной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.sort_values(by='Datum', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Churn'] = df['cnt_days_last_visit'].apply(lambda x: 1 if x >=7 else 0)\n",
    "df['Churn'] = df.groupby('mems_id')['Churn'].shift(-1)\n",
    "df=df.dropna(subset=['Churn'])\n",
    "df['Churn']=df['Churn'].astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разделение на папки для обучения и тестирования "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Fold_1'] = 0 \n",
    "df['Fold_2'] = 0 \n",
    "df['Fold_3'] = 0 \n",
    "df['Validation'] = 0\n",
    "\n",
    "df.loc[(df['Datum'] >= '2018-06-01') & (df['Datum'] <= '2018-09-30'), 'Fold_1'] = 'train'\n",
    "df.loc[(df['Datum'] >= '2018-10-15') & (df['Datum'] <= '2018-11-30'), 'Fold_1'] = 'test'\n",
    "df.loc[(df['Datum'] >= '2018-08-01') & (df['Datum'] <= '2018-12-31'), 'Fold_2'] = 'train'\n",
    "df.loc[(df['Datum'] >= '2019-01-15') & (df['Datum'] <= '2019-02-28'), 'Fold_2'] = 'test'\n",
    "df.loc[(df['Datum'] >= '2018-10-01') & (df['Datum'] <= '2019-02-28'), 'Fold_3'] = 'train'\n",
    "df.loc[(df['Datum'] >= '2019-03-15') & (df['Datum'] <= '2019-04-30'), 'Fold_3'] = 'test'\n",
    "df.loc[(df['Datum'] >= '2018-07-01') & (df['Datum'] <= '2019-03-31'), 'Validation'] = 'train'\n",
    "df.loc[(df['Datum'] >= '2019-06-01') & (df['Datum'] <= '2019-08-31'), 'Validation'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_hdf('/mnt/cda/week_churn_kat_1802.hdf', \"df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Считываем собранный файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf('/mnt/cda/week_churn_kat_1802.hdf', \"df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во уникальных клиентов 2027802\n",
      "\n",
      "Кол-во дат за весь период 61\n",
      "\n",
      "Первая дата 2018-06-03 00:00:00\n",
      "\n",
      "Последняя дата 2019-07-28 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print (\"Кол-во уникальных клиентов\", df['mems_id'].nunique())\n",
    "print ()\n",
    "print (\"Кол-во дат за весь период\", df['Datum'].nunique())\n",
    "print ()\n",
    "print (\"Первая дата\", df['Datum'].min())\n",
    "print ()\n",
    "print (\"Последняя дата\", df['Datum'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем набор данных для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cv = df[(df['Fold_1'] == 'train') | (df['Fold_2'] == 'train') |\\\n",
    "              (df['Fold_1'] == 'test') | (df['Fold_2'] == 'test')|\\\n",
    "             (df['Fold_3'] == 'train') | (df['Fold_3'] == 'test')].sample(500000).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Индексы данных для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ind_1 = train_cv[train_cv['Fold_1'] == 'train'].index.values.astype(int)\n",
    "test_ind_1 = train_cv[train_cv['Fold_1'] == 'test'].index.values.astype(int)\n",
    "train_ind_2 = train_cv[train_cv['Fold_2'] == 'train'].index.values.astype(int)\n",
    "test_ind_2 = train_cv[train_cv['Fold_2'] == 'test'].index.values.astype(int)\n",
    "train_ind_3 = train_cv[train_cv['Fold_3'] == 'train'].index.values.astype(int)\n",
    "test_ind_3 = train_cv[train_cv['Fold_3'] == 'test'].index.values.astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Целевая переменная и признаки для обучения модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер тестовой и убочающей выборки (500000, 42) (500000,)\n"
     ]
    }
   ],
   "source": [
    "y_train_cv = train_cv['Churn']\n",
    "X_train_cv = train_cv.drop(['index', 'Churn', 'mems_id', 'Datum', \n",
    "                              'Fold_1', 'Fold_2', 'Fold_3', 'Validation'],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Бизнес метрика для обучения модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_asymmetric_train(  y_true, y_pred ):# для грида такой порядок переменных\n",
    "    function=np.where((y_pred>0.5)&(y_true==0), -1000, 0)\n",
    "    function2=np.where((y_pred>0.5)&(y_true==1), 1, 0)\n",
    "    res=np.mean(function+function2).astype(float)\n",
    "    return  res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "my_func = make_scorer(custom_asymmetric_train, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генератор для разделения на обучающую и тестовую выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(train_cv):\n",
    "    i = 1\n",
    "    while i <= 3:\n",
    "        train_ind_1 = train_cv[train_cv['Fold_'+str(i)] == 'train'].index.values.astype(int)\n",
    "        test_ind_1 = train_cv[train_cv['Fold_'+str(i)] == 'test'].index.values.astype(int)\n",
    "        yield train_ind_1, test_ind_1\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = lgbm.LGBMClassifier(silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridParams = {\n",
    "    'learning_rate': [0.5, 0.2, 0.7],\n",
    "    'n_estimators':  [450, 500, 550],\n",
    "    'num_leaves': [6, 5, 4, 3],\n",
    "    'boosting_type' : ['rf'],\n",
    "    'objective' : ['binary'],\n",
    "    'random_state' : [501],\n",
    "    \"max_depth\":[2, 3, 4, 5],\n",
    "    'bagging_fraction':[0.1 ,0.3, 0.5,  0.6],\n",
    "    'bagging_freq': [1],\n",
    "    'colsample_bytree' : [0.5, 0.7, 1],\n",
    "    'subsample' : [0.1, 0.5],\n",
    "    'reg_alpha' : [5, 3, 1],\n",
    "    'reg_lambda' : [0.4, 0.6, 0.8, 1]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15552 candidates, totalling 46656 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=11)]: Using backend LokyBackend with 11 concurrent workers.\n",
      "[Parallel(n_jobs=11)]: Done  10 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=11)]: Done 106 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=11)]: Done 266 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=11)]: Done 490 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=11)]: Done 778 tasks      | elapsed: 73.3min\n",
      "[Parallel(n_jobs=11)]: Done 1130 tasks      | elapsed: 79.4min\n",
      "[Parallel(n_jobs=11)]: Done 1546 tasks      | elapsed: 86.6min\n",
      "[Parallel(n_jobs=11)]: Done 2026 tasks      | elapsed: 94.8min\n",
      "[Parallel(n_jobs=11)]: Done 2570 tasks      | elapsed: 104.6min\n",
      "[Parallel(n_jobs=11)]: Done 3178 tasks      | elapsed: 115.3min\n",
      "[Parallel(n_jobs=11)]: Done 3850 tasks      | elapsed: 127.0min\n",
      "[Parallel(n_jobs=11)]: Done 4586 tasks      | elapsed: 139.6min\n",
      "[Parallel(n_jobs=11)]: Done 5386 tasks      | elapsed: 153.7min\n",
      "[Parallel(n_jobs=11)]: Done 6250 tasks      | elapsed: 170.9min\n",
      "[Parallel(n_jobs=11)]: Done 7178 tasks      | elapsed: 189.5min\n",
      "[Parallel(n_jobs=11)]: Done 8170 tasks      | elapsed: 209.9min\n",
      "[Parallel(n_jobs=11)]: Done 9226 tasks      | elapsed: 230.8min\n",
      "[Parallel(n_jobs=11)]: Done 10346 tasks      | elapsed: 253.4min\n",
      "[Parallel(n_jobs=11)]: Done 11530 tasks      | elapsed: 281.3min\n",
      "[Parallel(n_jobs=11)]: Done 12778 tasks      | elapsed: 311.0min\n",
      "[Parallel(n_jobs=11)]: Done 14090 tasks      | elapsed: 342.6min\n",
      "[Parallel(n_jobs=11)]: Done 15466 tasks      | elapsed: 375.7min\n",
      "[Parallel(n_jobs=11)]: Done 16906 tasks      | elapsed: 401.2min\n",
      "[Parallel(n_jobs=11)]: Done 18410 tasks      | elapsed: 427.2min\n",
      "[Parallel(n_jobs=11)]: Done 19978 tasks      | elapsed: 454.5min\n",
      "[Parallel(n_jobs=11)]: Done 21610 tasks      | elapsed: 485.0min\n",
      "[Parallel(n_jobs=11)]: Done 23306 tasks      | elapsed: 518.9min\n",
      "[Parallel(n_jobs=11)]: Done 25066 tasks      | elapsed: 554.2min\n",
      "[Parallel(n_jobs=11)]: Done 26890 tasks      | elapsed: 594.1min\n",
      "[Parallel(n_jobs=11)]: Done 28778 tasks      | elapsed: 639.3min\n",
      "[Parallel(n_jobs=11)]: Done 30730 tasks      | elapsed: 686.1min\n",
      "[Parallel(n_jobs=11)]: Done 32746 tasks      | elapsed: 723.5min\n",
      "[Parallel(n_jobs=11)]: Done 34826 tasks      | elapsed: 819.6min\n",
      "[Parallel(n_jobs=11)]: Done 36970 tasks      | elapsed: 858.2min\n",
      "[Parallel(n_jobs=11)]: Done 39178 tasks      | elapsed: 902.6min\n",
      "[Parallel(n_jobs=11)]: Done 41450 tasks      | elapsed: 948.1min\n",
      "[Parallel(n_jobs=11)]: Done 43786 tasks      | elapsed: 1003.3min\n",
      "[Parallel(n_jobs=11)]: Done 46186 tasks      | elapsed: 1061.2min\n",
      "[Parallel(n_jobs=11)]: Done 46656 out of 46656 | elapsed: 1072.6min finished\n"
     ]
    }
   ],
   "source": [
    "grid_lgbm = GridSearchCV(mdl, gridParams,\n",
    "                        verbose=3,\n",
    "                        cv = generator(train_cv),\n",
    "                         n_jobs=11, scoring=my_func)\n",
    "\n",
    "grid_3 = grid_lgbm.fit(X_train_cv, y_train_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ошибка на обучении:\", grid_3.best_score_)\n",
    "print(\"Модель с лучшими параметрами:\", grid_3.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучающий и тестовый набор данных для модели с лучшими параметрами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df[df['Validation'] == 'test']\n",
    "\n",
    "\n",
    "y_test = df_test['Churn']\n",
    "X_test = df_test.drop(['Churn', 'mems_id', 'Datum', \n",
    "                              'Fold_1', 'Fold_2', 'Fold_3', 'Validation'], axis=1)\n",
    "\n",
    "df_train = df[df['Validation'] == 'train']\n",
    "\n",
    "y_train = df_train['Churn']\n",
    "X_train = df_train.drop(['Churn', 'mems_id', 'Datum', \n",
    "                              'Fold_1', 'Fold_2', 'Fold_3', 'Validation'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели с ранним завершением, чтобы выбрать лучшую модель по бизнес метрике "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[5]\ttraining's busines_metric: -170.635\n",
      "[10]\ttraining's busines_metric: -147.465\n",
      "[15]\ttraining's busines_metric: -140.648\n",
      "[20]\ttraining's busines_metric: -138.333\n",
      "[25]\ttraining's busines_metric: -138.203\n",
      "[30]\ttraining's busines_metric: -136.527\n",
      "[35]\ttraining's busines_metric: -135.522\n",
      "[40]\ttraining's busines_metric: -133.938\n",
      "[45]\ttraining's busines_metric: -133.693\n",
      "[50]\ttraining's busines_metric: -132.897\n",
      "[55]\ttraining's busines_metric: -132.474\n",
      "[60]\ttraining's busines_metric: -132.771\n",
      "[65]\ttraining's busines_metric: -133.429\n",
      "[70]\ttraining's busines_metric: -133.756\n",
      "[75]\ttraining's busines_metric: -133.76\n",
      "[80]\ttraining's busines_metric: -133.829\n",
      "[85]\ttraining's busines_metric: -133.841\n",
      "[90]\ttraining's busines_metric: -134.036\n",
      "[95]\ttraining's busines_metric: -134.252\n",
      "[100]\ttraining's busines_metric: -134.501\n",
      "[105]\ttraining's busines_metric: -133.898\n",
      "[110]\ttraining's busines_metric: -134.12\n",
      "[115]\ttraining's busines_metric: -133.903\n",
      "[120]\ttraining's busines_metric: -134.147\n",
      "[125]\ttraining's busines_metric: -134.037\n",
      "[130]\ttraining's busines_metric: -134.428\n",
      "[135]\ttraining's busines_metric: -134.508\n",
      "[140]\ttraining's busines_metric: -134.506\n",
      "[145]\ttraining's busines_metric: -134.368\n",
      "[150]\ttraining's busines_metric: -134.548\n",
      "[155]\ttraining's busines_metric: -134.536\n",
      "[160]\ttraining's busines_metric: -134.813\n",
      "[165]\ttraining's busines_metric: -134.958\n",
      "[170]\ttraining's busines_metric: -134.816\n",
      "[175]\ttraining's busines_metric: -134.626\n",
      "[180]\ttraining's busines_metric: -134.685\n",
      "[185]\ttraining's busines_metric: -134.955\n",
      "[190]\ttraining's busines_metric: -135.028\n",
      "[195]\ttraining's busines_metric: -135.011\n",
      "[200]\ttraining's busines_metric: -135.132\n",
      "[205]\ttraining's busines_metric: -134.875\n",
      "[210]\ttraining's busines_metric: -134.918\n",
      "[215]\ttraining's busines_metric: -134.819\n",
      "[220]\ttraining's busines_metric: -134.588\n",
      "[225]\ttraining's busines_metric: -134.58\n",
      "[230]\ttraining's busines_metric: -134.532\n",
      "[235]\ttraining's busines_metric: -134.624\n",
      "[240]\ttraining's busines_metric: -134.555\n",
      "[245]\ttraining's busines_metric: -134.683\n",
      "[250]\ttraining's busines_metric: -134.834\n",
      "[255]\ttraining's busines_metric: -134.71\n",
      "[260]\ttraining's busines_metric: -134.738\n",
      "[265]\ttraining's busines_metric: -134.67\n",
      "[270]\ttraining's busines_metric: -134.689\n",
      "[275]\ttraining's busines_metric: -134.803\n",
      "[280]\ttraining's busines_metric: -134.664\n",
      "[285]\ttraining's busines_metric: -134.796\n",
      "[290]\ttraining's busines_metric: -134.709\n",
      "[295]\ttraining's busines_metric: -134.702\n",
      "[300]\ttraining's busines_metric: -134.63\n",
      "[305]\ttraining's busines_metric: -134.758\n",
      "[310]\ttraining's busines_metric: -134.738\n",
      "[315]\ttraining's busines_metric: -134.761\n",
      "[320]\ttraining's busines_metric: -134.772\n",
      "[325]\ttraining's busines_metric: -134.905\n",
      "[330]\ttraining's busines_metric: -134.741\n",
      "[335]\ttraining's busines_metric: -134.797\n",
      "[340]\ttraining's busines_metric: -134.776\n",
      "[345]\ttraining's busines_metric: -134.89\n",
      "[350]\ttraining's busines_metric: -134.593\n",
      "[355]\ttraining's busines_metric: -134.515\n",
      "[360]\ttraining's busines_metric: -134.531\n",
      "[365]\ttraining's busines_metric: -134.559\n",
      "[370]\ttraining's busines_metric: -134.516\n",
      "[375]\ttraining's busines_metric: -134.618\n",
      "[380]\ttraining's busines_metric: -134.661\n",
      "[385]\ttraining's busines_metric: -134.64\n",
      "[390]\ttraining's busines_metric: -134.441\n",
      "[395]\ttraining's busines_metric: -134.442\n",
      "[400]\ttraining's busines_metric: -134.511\n",
      "[405]\ttraining's busines_metric: -134.326\n",
      "[410]\ttraining's busines_metric: -134.342\n",
      "[415]\ttraining's busines_metric: -134.405\n",
      "[420]\ttraining's busines_metric: -134.817\n",
      "[425]\ttraining's busines_metric: -134.768\n",
      "[430]\ttraining's busines_metric: -134.642\n",
      "[435]\ttraining's busines_metric: -134.633\n",
      "[440]\ttraining's busines_metric: -134.565\n",
      "[445]\ttraining's busines_metric: -134.451\n",
      "[450]\ttraining's busines_metric: -134.502\n",
      "[455]\ttraining's busines_metric: -134.38\n",
      "[460]\ttraining's busines_metric: -134.402\n",
      "[465]\ttraining's busines_metric: -134.487\n",
      "[470]\ttraining's busines_metric: -134.419\n",
      "[475]\ttraining's busines_metric: -134.393\n",
      "[480]\ttraining's busines_metric: -134.301\n",
      "[485]\ttraining's busines_metric: -134.293\n",
      "[490]\ttraining's busines_metric: -134.356\n",
      "[495]\ttraining's busines_metric: -134.285\n",
      "[500]\ttraining's busines_metric: -134.234\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[56]\ttraining's busines_metric: -132.138\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(bagging_fraction=0.3, boosting_type='gbdt', class_weight=None,\n",
       "               colsample_bytree=0.5, importance_type='split', learning_rate=0.2,\n",
       "               max_depth=2, metric='custom', min_child_samples=20,\n",
       "               min_child_weight=0.001, min_split_gain=0.0, n_estimators=500,\n",
       "               n_jobs=-1, num_leaves=3, objective='binary', random_state=501,\n",
       "               reg_alpha=0.1, reg_lambda=1, silent=True, subsample=0.1,\n",
       "               subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl_metric = lgbm.LGBMClassifier(**grid_3.best_params_, metric='custom')\n",
    "\n",
    "mdl_metric.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "   eval_metric=custom_asymmetric_train,\n",
    "    early_stopping_rounds=1000,\n",
    "    verbose=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict, {'training': {'busines_metric': -132.1383352914261}})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl_metric.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка процентного соотношения ошибок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_percent(y_pred, y_true):\n",
    "    residual = (2*y_true - y_pred)\n",
    "    true=np.sum(np.where(residual==1, 1, 0))/len(y_true)\n",
    "    false=np.sum(np.where(residual==-1, 1, 0))/len(y_true)\n",
    "    falsep=np.sum(np.where(residual==2, 1, 0))/len(y_true)\n",
    "    return 'true_neg:', true, 'false_neg:', false, 'false_p:', falsep, 'true_p:', 1-false-true-falsep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('true_neg:',\n",
       " 0.6550504197068816,\n",
       " 'false_neg:',\n",
       " 0.13279338571113297,\n",
       " 'false_p:',\n",
       " 0.061432373069966385,\n",
       " 'true_p:',\n",
       " 0.15072382151201905)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_percent(mdl_metric.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 0.769\n",
      "Accuracy score (validation): 0.806\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score (training): {0:.3f}\".format(mdl_metric.score(X_train, y_train)))\n",
    "print(\"Accuracy score (validation): {0:.3f}\".format(mdl_metric.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Churn_forest2802.pkl\", 'wb') as fid:\n",
    "    pickle.dump(mdl_metric, fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
